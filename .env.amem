# A-mem Environment Configuration
# Source this file before running A-mem: source .env.amem

# Disable HuggingFace implicit token (fixes 401 errors)
export HF_HUB_DISABLE_IMPLICIT_TOKEN=1

# Ollama configuration
export OLLAMA_HOST=http://localhost:11434
export OLLAMA_MODEL=llama3.2

# Python virtual environment
export PATH="$HOME/memory-layer/.venv/bin:$PATH"

# Optional: Disable HuggingFace telemetry
export HF_HUB_DISABLE_TELEMETRY=1

echo "âœ… A-mem environment configured"
echo "   LLM: Ollama (llama3.2)"
echo "   Embeddings: all-MiniLM-L6-v2"
echo "   Python: $(which python)"
